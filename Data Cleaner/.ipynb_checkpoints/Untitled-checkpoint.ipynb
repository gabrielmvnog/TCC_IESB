{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como cometer suicídio sem dx a mãe triste</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estou nova demais p cometer esse suicídio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Nunca dirijo meu carro por cima de uma ponte ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nem imagino como seria minha vida sem esse gat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A vida tá me testando para ver qual  vou comet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  labels\n",
       "0          Como cometer suicídio sem dx a mãe triste       0\n",
       "1          Estou nova demais p cometer esse suicídio       0\n",
       "2  \"Nunca dirijo meu carro por cima de uma ponte ...       0\n",
       "3  Nem imagino como seria minha vida sem esse gat...       0\n",
       "4  A vida tá me testando para ver qual  vou comet...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Dataset_final.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1063.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.503293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            labels\n",
       "count  1063.000000\n",
       "mean      0.503293\n",
       "std       0.500225\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1063 entries, 0 to 1062\n",
      "Data columns (total 2 columns):\n",
      "texts     1063 non-null object\n",
      "labels    1063 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 16.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Normalize to Lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove Accent\n",
    "    text = unidecode.unidecode(text)\n",
    "    \n",
    "    # Split ponctuation\n",
    "    text = ' '.join(re.findall(r\"[\\w]+|[\" + string.punctuation + r\"]\",text))\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove Stopwords\n",
    "#     text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\n",
    "\n",
    "new_df['texts'] = new_df['texts'].apply(clean_text)\n",
    "new_df['lenght'] = new_df['texts'].str.split().str.len()\n",
    "\n",
    "new_df = new_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1031.000000</td>\n",
       "      <td>1031.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.516004</td>\n",
       "      <td>10.636275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499986</td>\n",
       "      <td>6.765174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            labels       lenght\n",
       "count  1031.000000  1031.000000\n",
       "mean      0.516004    10.636275\n",
       "std       0.499986     6.765174\n",
       "min       0.000000     2.000000\n",
       "25%       0.000000     6.000000\n",
       "50%       1.000000     9.000000\n",
       "75%       1.000000    13.000000\n",
       "max       1.000000    57.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1031 entries, 0 to 1062\n",
      "Data columns (total 3 columns):\n",
      "texts     1031 non-null object\n",
      "labels    1031 non-null int64\n",
      "lenght    1031 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 32.2+ KB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = new_df['texts']\n",
    "labels = new_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(texts, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'gamma':['scale', 'auto']}\n",
    "svc = svm.SVC(kernel='rbf', probability=True)\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Treino com TF-IDF ===\n",
      "\n",
      "Fold 0 | Acurácia: 0.80%\n",
      "Fold 1 | Acurácia: 0.77%\n",
      "Fold 2 | Acurácia: 0.78%\n",
      "Fold 3 | Acurácia: 0.83%\n",
      "Fold 4 | Acurácia: 0.86%\n",
      "Fold 5 | Acurácia: 0.80%\n",
      "Fold 6 | Acurácia: 0.84%\n",
      "Fold 7 | Acurácia: 0.74%\n",
      "Fold 8 | Acurácia: 0.72%\n",
      "Fold 9 | Acurácia: 0.85%\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10)\n",
    "\n",
    "print(\"=== Treino com TF-IDF ===\\n\")\n",
    "for i, (train, test) in enumerate(folds.split(X_train, Y_train)):\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_data = vectorizer.fit_transform(X_train.iloc[train])\n",
    "    \n",
    "    clf = clf.fit(train_data, Y_train.iloc[train])\n",
    "    \n",
    "    test_data = vectorizer.transform(X_train.iloc[test])\n",
    "\n",
    "    print(f\"Fold {i} | Acurácia: {clf.score(test_data, Y_train.iloc[test]):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214969, 328980)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_texts = [text.split() for text in new_df['texts']]\n",
    "vocab = ' '.join(new_df['texts']).split()\n",
    "\n",
    "embedding_size = 250\n",
    "model = Word2Vec(size=embedding_size, window=3, min_count=1, workers=4, sg=0)\n",
    "model.build_vocab(wv_texts, progress_per=10000)\n",
    "\n",
    "\n",
    "model.train(wv_texts, total_examples=model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('so', 0.9992678165435791),\n",
       " ('ultimamente', 0.9985920190811157),\n",
       " ('quero', 0.9985347986221313),\n",
       " ('deus', 0.9984744191169739),\n",
       " ('posso', 0.9983900189399719),\n",
       " ('sera', 0.9983232021331787),\n",
       " ('deitar', 0.9983208179473877),\n",
       " ('eu', 0.9982663989067078),\n",
       " ('chorar', 0.9982332587242126),\n",
       " ('sono', 0.9981982707977295)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"morrer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tudo', 0.9971909523010254),\n",
       " ('de', 0.9957691431045532),\n",
       " ('serio', 0.995643138885498),\n",
       " ('juro', 0.9954697489738464),\n",
       " ('ai', 0.9950079321861267),\n",
       " ('amorosa', 0.9949986338615417),\n",
       " ('especie', 0.9948625564575195),\n",
       " ('olha', 0.9947174787521362),\n",
       " ('literalmente', 0.9947168827056885),\n",
       " ('namoral', 0.9945694208145142)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"desisto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solteira', 0.9961459040641785),\n",
       " ('de', 0.9960996508598328),\n",
       " ('serio', 0.9958281517028809),\n",
       " ('estudante', 0.9952219724655151),\n",
       " ('sofrida', 0.9951193332672119),\n",
       " ('affs', 0.9946573376655579),\n",
       " ('ai', 0.9945566654205322),\n",
       " ('desanimo', 0.9945402145385742),\n",
       " ('conversar', 0.994526207447052),\n",
       " ('dormi', 0.9944660067558289)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"cansei\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = model.wv.index2word\n",
    "\n",
    "def avg_feat_vector(sentece):\n",
    "    words = sentece.split()\n",
    "    feat_vec = np.zeros((embedding_size, ), dtype=\"float\")\n",
    "    n_words = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word:\n",
    "            n_words += 1\n",
    "            feat_vec = np.add(feat_vec, model.wv.__getitem__(word))\n",
    "    if (n_words > 0):\n",
    "        feat_vec = np.divide(feat_vec, n_words)\n",
    "    \n",
    "    return feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Treino com Word2Vec ===\n",
      "\n",
      "Fold 0 | Acurácia: 0.80%\n",
      "Fold 1 | Acurácia: 0.66%\n",
      "Fold 2 | Acurácia: 0.72%\n",
      "Fold 3 | Acurácia: 0.70%\n",
      "Fold 4 | Acurácia: 0.65%\n",
      "Fold 5 | Acurácia: 0.70%\n",
      "Fold 6 | Acurácia: 0.58%\n",
      "Fold 7 | Acurácia: 0.54%\n",
      "Fold 8 | Acurácia: 0.71%\n",
      "Fold 9 | Acurácia: 0.66%\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Treino com Word2Vec ===\\n\")\n",
    "for i, (train, test) in enumerate(folds.split(X_train, Y_train)):\n",
    "    \n",
    "    train_data = X_train.iloc[train].apply(avg_feat_vector)\n",
    "    \n",
    "    clf = clf.fit(list(train_data), Y_train.iloc[train])\n",
    "    \n",
    "    test_data = list(X_train.iloc[test].apply(avg_feat_vector))\n",
    "\n",
    "    print(f\"Fold {i} | Acurácia: {clf.score(test_data, Y_train.iloc[test]):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-3.6.7",
   "language": "python",
   "name": "nlp-3.6.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
